{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa47ec1",
   "metadata": {},
   "source": [
    "# Flexion Angle Detection\n",
    "\n",
    "The following cells are able to plot a human pose estimate on a pre-recorded video stream and get the angle between specific joints of the right arm.\n",
    "\n",
    "## Key Aspects\n",
    "- Runs on OpenCV - machine learning applicable library for computer vision\n",
    "- Real time application\n",
    "- Can run on CPU (later to be optimized for Nvidia GPU cores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe9ca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required packages and dependancies\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import math\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fef4522",
   "metadata": {},
   "source": [
    "## Defining a class poseDetector with predefined joints pose, position and angle functions\n",
    "The cell below is to initiate the pose detector class as directed from MediaPipe with various parameters in the class for pose detection.\n",
    "\n",
    "We can have different classes for face, hand, pose and the angle but all of them have associated attributes hence a single class called poseDetector with diferent functions to be called later on in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6029fd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class poseDetector():\n",
    "\n",
    "    def __init__(self, mode=False, complexity=1, smooth_landmarks=True, \n",
    "                 segmentation=False, smooth_segmentation=True, detectionCon=0.5, trackCon=0.5):\n",
    "        \n",
    "        self.mode = mode\n",
    "        self.complexity = complexity\n",
    "        self.smooth_landmarks = smooth_landmarks\n",
    "        self.segmentation = segmentation\n",
    "        self.smooth_segmentation = smooth_segmentation\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        self.mpPose = mp.solutions.pose\n",
    "        self.pose = self.mpPose.Pose(self.mode, \n",
    "                                     self.complexity, \n",
    "                                     self.smooth_landmarks,\n",
    "                                     self.segmentation,\n",
    "                                     self.smooth_segmentation,\n",
    "                                     self.detectionCon, \n",
    "                                     self.trackCon)\n",
    "    #function to find the pose    \n",
    "    def findPose(self, img, draw=True):\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.pose.process(imgRGB)\n",
    "        if self.results.pose_landmarks:\n",
    "            if draw:\n",
    "                self.mpDraw.draw_landmarks(img, self.results.pose_landmarks,\n",
    "                                           self.mpPose.POSE_CONNECTIONS)\n",
    "        return img\n",
    "    \n",
    "    #funtion to return the position of all the joints in the image/video\n",
    "    def findPosition(self, img, draw=True):\n",
    "        self.lmList = []\n",
    "        if self.results.pose_landmarks:\n",
    "            for id, lm in enumerate(self.results.pose_landmarks.landmark):\n",
    "                h, w, c = img.shape\n",
    "                # print(id, lm)\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                self.lmList.append([id, cx, cy])\n",
    "                if draw:\n",
    "                    cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)\n",
    "        return self.lmList\n",
    "\n",
    "    #function to return the angle between joints p1,p2,p3\n",
    "    def findAngle(self, img, p1, p2, p3, draw=True):\n",
    "        # Get the landmarks/positions of the joints\n",
    "        x1, y1 = self.lmList[p1][1:]\n",
    "        x2, y2 = self.lmList[p2][1:]\n",
    "        x3, y3 = self.lmList[p3][1:]\n",
    "\n",
    "        # Calculate the Angle between the mapped joints\n",
    "        angle = math.degrees(math.atan2(y3 - y2, x3 - x2) -\n",
    "                             math.atan2(y1 - y2, x1 - x2))\n",
    "        if angle < 0:\n",
    "            angle += 360\n",
    "        # print(angle)\n",
    "\n",
    "        # Draw the selected joints and the line joining them\n",
    "        if draw:\n",
    "            #highlighting the skeleton connecting the joints\n",
    "            cv2.line(img, (x1, y1), (x2, y2), (255, 255, 255), 3)\n",
    "            cv2.line(img, (x3, y3), (x2, y2), (255, 255, 255), 3)\n",
    "            #highlighting the joints with bigger circles\n",
    "            cv2.circle(img, (x1, y1), 10, (0, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x1, y1), 15, (0, 0, 255), 2)\n",
    "            cv2.circle(img, (x2, y2), 10, (0, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x2, y2), 15, (0, 0, 255), 2)\n",
    "            cv2.circle(img, (x3, y3), 10, (0, 0, 255), cv2.FILLED)\n",
    "            cv2.circle(img, (x3, y3), 15, (0, 0, 255), 2)\n",
    "            # Drawing the value of the angle on the highlighted joint\n",
    "            cv2.putText(img, str(int(angle)), (x2 - 50, y2 + 50),\n",
    "                        cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 255), 2)\n",
    "        return angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8638d",
   "metadata": {},
   "source": [
    "## Pose on image from poseDetector\n",
    "The cell below is capable of plotting the human pose on images/videos of human beings in different postures.\n",
    "\n",
    "The poseDetector class defined in the cells above is imported and a defined function is used to plot the human pose on the image/video provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9920b1ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m success, img \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#for image input\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#img = cv2.imread(\"TestVideo/test3.jpg\")\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m900\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m700\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mflip(img, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m img \u001b[38;5;241m=\u001b[39m detector\u001b[38;5;241m.\u001b[39mfindPose(img, \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.6.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"TestVideo/FlexTest.mp4\")\n",
    "detector = poseDetector() #from class poseDetector in cells above \n",
    "\n",
    "while True:\n",
    "    #for video input\n",
    "    success, img = cap.read()\n",
    "    #for image input\n",
    "    #img = cv2.imread(\"TestVideo/test3.jpg\")\n",
    "    \n",
    "    img = cv2.resize(img, (900,700))\n",
    "    img = cv2.flip(img, 0)\n",
    "\n",
    "    img = detector.findPose(img, False)\n",
    "    jointsList = detector.findPosition(img, False)\n",
    "    #print(jointsList)\n",
    "    \n",
    "    #Defining the 3 joints whose angle you need to find\n",
    "    if len(jointsList) != 0:\n",
    "        #left leg\n",
    "        #detector.findAngle(img, 23, 25, 27)\n",
    "        #right leg\n",
    "        #detector.findAngle(img, 24, 26, 28)\n",
    "        #right arm\n",
    "        #detector.findAngle(img, 12, 14, 16)\n",
    "        #left arm\n",
    "        detector.findAngle(img, 11, 13, 15)\n",
    "        \n",
    "    cv2.imshow(\"image\", img)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74403cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a98472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
